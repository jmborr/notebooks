{
 "metadata": {
  "name": "",
  "signature": "sha256:61c0fbfd656da0101a745e69b0bd7a5f1e2631a7f05f20bfd277773d1996e736"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Dynamics Pair Distribution Function (DPDF)</h1>\n",
      "\n",
      "<a id='Table of Contents'></a><h3>Table of Contents</h3>\n",
      "<a href='#Syntax'>HTML and MARKDOWN SYNTAX EXAMPLES</a></br>\n",
      "<a href='#People'>People</a></br>\n",
      "<a href='#Goal'>Goals</a></br>\n",
      "\n",
      "<a href='#meetings'><h4>Meetings</h4></a>\n",
      "\n",
      "* <a href='#meetings.meeting1'>First meeting with Wojciech</a></br>\n",
      "* <a href='#meetings.June26'>June 26</a></br>\n",
      "\n",
      "<a href='#benchmarkRun'>Benchmark run</a></br>\n",
      "<a href='#detectorGaps'>Gaps in ARCS detectors</a></br>\n",
      "<a href='#reduceBenchmark'>Early reduction of benchmark</a></br>\n",
      "<a href='#DPDFreduction'>DPDFreduction algorithm</a></br>\n",
      "<a href='#sshfs'>Explain Wojtek how to mount /SNS wiht SSH</a></br>\n",
      "\n",
      "<a href='#SectionTag'><h4>Section title here</h4></a>\n",
      "\n",
      "* <a href='#SectionTag.subsection1Tag'>Subsection 1 title here</a></br>\n",
      "* <a href='#SectionTag.subsection2Tag'>Subsection 2 title here</a></br>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='People'></a><h3>People</h3>\n",
      "\n",
      "* Wojciech Dmowski <wdmowski@utk.edu>\n",
      "* Stuart Campbell\n",
      "* Andrei Savici"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='Goals'></a><h3>Goal</h3>\n",
      "\n",
      "Reduction workflow including:\n",
      "\n",
      "* Data reduction\n",
      "* Removal of trends in S(Q,E) via model fitting\n",
      "* Fourier transform"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='meetings'></a><h2>Meetings</h2>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='meetings.meeting1'></a><h3>First meeting with Wojciech</h3>\n",
      "Wojciech described for us the workflow that he follows to produce g(r,E) starting from the auto-reduced \"nxspe\" file. The worflow is detailed in the script [flow.txt](files/meetings/June_11_2015/flow.txt)\n",
      "\n",
      "Step 0. Translate from nxspe to spe format with [spe_rw2.f](files/meetings/June_11_2015/spe_rw2.f). The nxspe file is a histogram $S(\\theta,\\phi,E)$, which is then integrated in $\\phi$ to yield $S(\\theta,E)$ and saved as an \"spe\" file (ASCII).\n",
      "\n",
      "Step 1.  This histogram shows sudden changes in intensity for certain values of $\\theta$, namely:\n",
      "<pre>7\n",
      "74.85\n",
      "75.346\n",
      "75.746\n",
      "76.746\n",
      "105.85\n",
      "106.35\n",
      "106.85</pre>\n",
      "\n",
      "These are thought to be due to gaps in the detectors of the <b>ARCS</b> beamline. Values stored in [det.txt](files/meetings/June_11_2015/det.txt). Wojciech uses a linear interpolation routine ([spe_interp.f](files/meetings/June_11_2015/spe_interp.f)) to assign intensity values at these angles, based on neighboring values along an iso-energy line. in the $(\\theta,E)$ phase space.\n",
      "\n",
      "Step 2. A background file containing the empty can is treated in the same way, then substracted from the data.\n",
      "\n",
      "Step 3. A $\\theta$ range is considered, outside of which the data is not considered trustworthy.\n",
      "\n",
      "Step 4. Conversion $S(\\theta,E) \\rightarrow S(Q,E)$.\n",
      "\n",
      "Step 5. Slicing of S(Q,E) as a rebin in inergy with \"thick\" energy binning (typical values in the 0.5 to 2 meV range), in order to gain enough statistical significance. The resulting number of slices, or spectra, is in the order of $10^2$. Slicing performed with \n",
      "[qcutall.f](files/meetings/June_11_2015/qcutall.f)\n",
      " \n",
      "<center><a href=\"files/meetings/June_11_2015/step5.png\"><img src=\"files/meetings/June_11_2015/step5.png\" width=\"300\" height=\"250\" alt=\"meetings/June_11_2015/step5.png\"></a> <br/><i>meetings/June_11_2015/step5.png</i></center>\n",
      "    \n",
      "Step6. Removal of the trend over which the fluctuations are superimposed.\n",
      "\n",
      "<center><a href=\"files/meetings/June_11_2015/step6.png\"><img src=\"files/meetings/June_11_2015/step6.png\" width=\"300\" height=\"250\" alt=\"meetings/June_11_2015/step6.png\"></a> <br/><i>meetings/June_11_2015/step6.png</i></center>\n",
      "\n",
      "This is the most complex step, and includes a fitting of the spectra to different models based on phonon expansion. The model most commonly used to fit the trend is a Gaussian. The fit is done to every spectrum, and independently of each other. A sequential fitting of the spectra is usually performed, however the chosen model may stop being useful when certain ranges of the energy are reached.\n",
      "\n",
      "The fits models are coded in the following fortran programs: \n",
      "\n",
      "* [dbfit0.f](files/meetings/June_11_2015/dbfit0.f), $YFIT=ac(1) + ac(2)x + ac(3)x^2$ (Quadratic)\n",
      "* [dbfit1.f](files/meetings/June_11_2015/dbfit1.f), $YFIT=ac(1)+ac(2)e^{-ac(3)x^2}$ (Gaussian)\n",
      "* [dbfit2.f](files/meetings/June_11_2015/dbfit2.f), $YFIT=ac(1)+[ac(2)+ac(3)x^2]e^{-ac(4)x^2}$\n",
      "* [dbfit2sm.f](files/meetings/June_11_2015/dbfit2sm.f) same a above but data is box-smmothed before fit\n",
      "* [dbfit3.f](files/meetings/June_11_2015/dbfit3.f) $YFIT=ac(1)+[ac(2)x^2+ac(3)x^4]e^{-ac(4)x^2}$\n",
      "\n",
      "The effects of the interpolation step can be observed as high frequency oscillations in the spectra at particular values of Q\n",
      "\n",
      "<center><a href=\"files/meetings/June_11_2015/step6b.png\"><img src=\"files/meetings/June_11_2015/step6b.png\" width=\"300\" height=\"250\" alt=\"meetings/June_11_2015/step6b.png\"></a> <br/><i>meetings/June_11_2015/step6b.png</i></center>\n",
      "\n",
      "Step 7. If the fitting is good, the spectra should fluctuate around S(Q,E)=0. Wojciech substract a flat background to make sure.\n",
      "\n",
      "<center><a href=\"files/meetings/June_11_2015/step7.png\"><img src=\"files/meetings/June_11_2015/step7.png\" width=\"300\" height=\"250\" alt=\"meetings/June_11_2015/step7.png\"></a> <br/><i>meetings/June_11_2015/step7.png</i></center>\n",
      "\n",
      "Step 8. Fourier transform $S(Q,E) \\rightarrow g(r,E)$. Wojciech had bad results with DFT, thus he uses the regular Fourier transform. Performed with [rdf-b4.f](files/meetings/June_11_2015/rdf-b4.f)\n",
      "\n",
      "<center><a href=\"files/meetings/June_11_2015/step8.png\"><img src=\"files/meetings/June_11_2015/step8.png\" width=\"300\" height=\"250\" alt=\"meetings/June_11_2015/step8.png\"></a> <br/><i>meetings/June_11_2015/step8.png</i></center>\n",
      "\n",
      "To summarize, these are the contents of workflow [flow.txt](files/meetings/June_11_2015/flow.txt) showing how to call the fortran programs:\n",
      "<pre>./spe_rw2 sep_in spe_out - small format conversion \n",
      "./spe_interp spe_in spe_out (reads det.dat) detector interpolation in 2th\n",
      "./spe_sub-plain data.specan.spe -> data-csub.spe\n",
      "./spe_rw3 data.spe data-esums.spe -80.25 (E_min) 4 (number of summed esteps) 2.4633 (Phi min) 135.80 (Phi max)\n",
      "sqe1 data.spe data.sqe  (reads sqe.inp file)\n",
      "./qcutall data.sqe dir/data\n",
      "run fits on q-cuts\n",
      "dbfit0          YFIT=ac(1) + ac(2)*x + ac(3)*x^2\n",
      "dbfit1          YFIT=AC(1)+ac(2)*exp(-ac(3)*x^2)\n",
      "dbfit2          YFIT=AC(1)+(ac(2)+ac(3)*x^2)*exp(-ac(4)*x^2)\n",
      "dbfit2sm        same a above but data is box-smmothed before fit\n",
      "dbfit3          YFIT=AC(1)+(ac(2)*x^2+ac(3)*x^2)*exp(-ac(4)*x^2)\n",
      "rdf-b4          reads *FIT* file and makes FT transform</pre>\n",
      "\n",
      "We end up with ~$10^2$ different $g(r,E)$ spectra, which Wojciech wishes to see as a 3D plot (or colored 2D plot). Also of interest would be a colored 3D plot of $g(r,E,T)$, with T being temperature or some other interetesting physical parameter."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='meetings.June26'></a><h3>June 26</h3>\n",
      "Requests regarding reduction:\n",
      "\n",
      "* Energy binning should be such that the bin containing the elastic line should have the center bin at E=0. Thus, if energy slice is $\\DeltaE$, the boundaries of the bin containing the elastic line shoudl be $-\\Delta E/2$ and $\\Delta E/2$.\n",
      "* Add option to remove background due to an empty can run.\n",
      "\n",
      "Request/comments regarding fitting procedure:\n",
      "\n",
      "* Make sure that the energy values used to label the fit workspaces for each slice should correspond to the center value of the slice.\n",
      "* Ability to interact with each fit, one by one. No need to do the fittings all at once. The best solution is an interface containing the fit wizard.\n",
      "\n",
      "Exploration of problems installing Mantid in RedHat 6:\n",
      "\n",
      "* Install a virtual RedHat 6 machine in my workstation and try to build Mantid."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='benchmarkRun'></a><h3>Benchmark run</h3>\n",
      "We'll be using the folling run as a benchmark of our workflow:\n",
      "<pre>-----------VANADIUM CALIBRATION AND MASKING-----------\n",
      "Calibration loaded from /SNS/lustre/ARCS/IPTS-8124/shared/AlMelt_Jan2015/mantidreduction/van56293.nxs\n",
      "\n",
      "-----------DATA REDUCTION-----------------------------\n",
      "Loaded data run from /SNS/ARCS/IPTS-8124/0/56415/NeXus/ARCS_56415_event.nxs\n",
      "Added data run from /SNS/ARCS/IPTS-8124/0/56416/NeXus/ARCS_56416_event.nxs\n",
      "Added data run from /SNS/ARCS/IPTS-8124/0/56417/NeXus/ARCS_56417_event.nxs\n",
      "Added data run from /SNS/ARCS/IPTS-8124/0/56418/NeXus/ARCS_56418_event.nxs\n",
      "Added data run from /SNS/ARCS/IPTS-8124/0/56419/NeXus/ARCS_56419_event.nxs\n",
      "Added data run from /SNS/ARCS/IPTS-8124/0/56420/NeXus/ARCS_56420_event.nxs\n",
      "Bad pulses have been filterd from the data file(s).\n",
      "Incident energy is calculated from monitor data.\n",
      "Ei =116.782810853 meV, t0 =20.0620963024 microseconds\n",
      "No time-independent background subtraction performed.\n",
      "Data normalized by proton charge (5403.77269707 micro-Ah), (19.4535817095 C).\n",
      "Data corrected for He3 Tube Efficiency.\n",
      "ki/kf factor has been applied to the data.\n",
      "Data binned with emin=-120.0, emax=115.0, ebin=0.5 meV.\n",
      "Data converted to differential cross section by dividing by the energy bin width.\n",
      "Data have been normalized and masked by the calibration file.</pre>\n",
      "These are the contents of file [Al_Melting_120meV_120p00_summary.txt](files/meetings/June_11_2015/Al_Melting_120meV_120p00_summary.txt).\n",
      "\n",
      "In subdirectory <i>benchmark/</i> we have the nexus events files (ARCS_56415_event.nxs, ARCS_56416_event.nxs, ARCS_56417_event.nxs,ARCS_56418_event.nxs, ARCS_56419_event.nxs, ARCS_56420_event.nxs) and the processed vandium file (van56293.nxs)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='detectorGaps'></a><h3>Gaps in ARCS detectors</h3>\n",
      "ARCS has three rows of detectors, each divided into squares. There are gaps between squares:\n",
      "\n",
      "<center><a href=\"files/detector_gaps/gaps.v2.png\"><img src=\"files/detector_gaps/gaps.v2.png\" width=\"400\" height=\"400\" alt=\"meetings/detector_gaps/gaps.v2.png\"></a> <br/><i>detector_gaps/gaps.v2.png</i></center>\n",
      "\n",
      "The above image shows the intensity of the benchmark set on the ARCS instrument. At 105 and 75 degrees, there is no intensity recorded because there is no cross section between detector area and the intensity rings corresponding to $\\theta$ equal to these angles."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='reduceBenchmark'></a><h3>Early reduction of benchmark</h3>\n",
      "In subdirectory <i>benchmark/</i> we have script [reduce.py](files/benchmark/reduce.py) which takes the events files and the processed vanadium for the benchmark and generates histograms S(\\theta,E), S(Q,E).\n",
      "The steps for the reduction are:\n",
      "\n",
      "* Load event files into a sinle workspace\n",
      "* Load the vanadium file\n",
      "* Retrieve the mask from the vanadium workspace, and apply it to the data\n",
      "* Obtain incident energy as the mean of the nominal Ei values. There is one nominal value per events file\n",
      "* Convert to energy transger. The output workspace is $S(detector-id,E)$\n",
      "* Convert to $S(\\theta,E)$\n",
      "* Convert vanadium data to $S(\\theta)$. For the processed vanadium, every detector has all energies into a single bin, so we get $S(\\theta)$ instead of $S(\\theta,E)$.\n",
      "* Convert $S(\\theta,E)$ to $S(Q,E)$, then rebin in |Q| and E. The output workspace is of type MDworkspace.\n",
      "* Slice the data by transforming to a Matrix2Dworkspace, with energy transfer along the vertical axis."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='DPDFreduction'></a><h3>DPDFreduction algorithm</h3>\n",
      "We create Mantid algorithm [DPDFreduction.py](files/reduction/DPDFreduction.py) that includes the following steps:\n",
      "\n",
      "* Load several event files into a sinle workspace.\n",
      "* Load the vanadium file\n",
      "* Retrieve the mask from the vanadium workspace, and apply it to the data\n",
      "* If not supplied by the user, obtain incident energy as the mean of the nominal indicent energy values in the logs\n",
      "* Convert to energy transger. The output workspace is $S(detector-id,E)$\n",
      "* Obtain maximum and minimum |Q| values, as well as dQ if not supplied by the user\n",
      "* Convert to $S(\\theta,E)$\n",
      "* Convert vanadium data to $S(\\theta)$. For the processed vanadium, every detector has all energies into a single bin, so we get $S(\\theta)$ instead of $S(\\theta,E)$.\n",
      "* Normalize by the vanadium intensity\n",
      "* Linear interpolation at angles $\\theta^*$ for which $S(\\theta^*,E)=0 \\ \\forall \\ E$\n",
      "* Convert $S(\\theta,E)$ to $S(Q,E)$, then rebin in |Q| and E. The output workspace is of type MDworkspace.\n",
      "* Slice the data by transforming to a Matrix2Dworkspace, with energy transfer along the vertical axis.\n",
      "\n",
      "The last step in the reduction, the slicing by executing algorithm <i>ConvertMDHistoToMatrixWorkspace</i> requires normalization <i>NumEventsNormalization</i>. Our input workspace has as many spectra as instrument detectors. Each detector has a 2D binning in Q and E. Each detector is at a particular $\\theta$ angle, thus E and Q are related by:\n",
      "\n",
      "$E(Q) \\rightarrow \\frac{\\hbar Q^2}{2m} =  2E_i + E -2\\sqrt{(E_i+E)E_i} \\ \\ \\cos\\theta$\n",
      "\n",
      "That means that only (Q,E) bins satisfying the above condition have counts. Thus for detector <i>i</i> we have number of counts $N_i(Q_j,E_k) \\neq 0$ if the $(Q_j, E_k)$ pair satisfy the above condition. This represents a trajectory in Q-E space.\n",
      "\n",
      "When we execute algorithm <i>ConvertMDHistoToMatrixWorkspace</i> with Q binning $\\Delta Q$ and E binning $\\Delta E$, we go detector by detectory and we look at the fragment of the Q(E) trajectory enclosed in the cell of Q-E phase space denoted by the corners $(Q,E)$, $(Q+\\Delta Q,E)$, $(Q,E+\\Delta E)$ and $(Q+\\Delta Q,E+\\Delta E)$. Thus we have for detector $i$ to look at the $(Q_j, E_k)$ pairs whithin this cell for detector $i$, with associated $N_i(Q_j,E_k)$ counts and associated scattering cross-section:\n",
      "\n",
      "($\\frac{d\\sigma^2}{dE d\\Omega})_{i,j,k} \\ \\ (Q_j,E_k) = \\frac{N_i(Q_j,E_k)}{d\\Omega \\delta E}$\n",
      "\n",
      "The scattering cross-section in the aforemention cell of dimensions $\\Delta Q$ x $\\Delta E$ is the <i>average</i> of all the scattering cross sections:\n",
      "\n",
      "$\\frac{d\\sigma^2}{\\Delta E d\\Omega}(Q,E) = \\sum\\limits_{i,j,k}(\\frac{d\\sigma^2}{\\delta E d\\Omega})_{i,j,k} \\ \\ (Q_j,E_k) \\cdot \\Pi_{Q,Q+\\Delta Q} \\ \\ \\ (Q_j) \\cdot \\Pi_{E,E+\\Delta E} \\ \\ \\ (E_k) / \\sum\\limits_{i,j,k} \\Pi_{Q,Q+\\Delta Q} \\ \\ \\ (Q_j) \\cdot \\Pi_{E,E+\\Delta E} \\ \\ \\ (E_k)$\n",
      "\n",
      "where $\\Pi_{a,b} \\ (x)$ is the [boxcar function](http://mathworld.wolfram.com/BoxcarFunction.html)\n",
      "\n",
      "<center><a href=\"files/reduction/DPDFreduction_window.png\"><img src=\"files/reduction/DPDFreduction_window.png\" width=\"300\" height=\"300\" alt=\"reduction/DPDFreduction_window.png\"></a> <br/><i>reduction/DPDFreduction_window.png</i></center>\n",
      "\n",
      "If we apply the reduction algorithm to the benchmark data, we obtain reduced file [DPDFreduction.nxs](files/benchmark/DPDFreduction.nxs) (downloadable from [here](https://www.dropbox.com/s/ipsrtvrh9oq8mt6/DPDFreduction.nxs?dl=0))\n",
      "\n",
      "The Structure factor stored in <i>DPDFreduction.nxs</i> viewed with sliceviewer from MantidPlot:\n",
      "\n",
      "<center><a href=\"files/benchmark/DPDFreduction.png\"><img src=\"files/benchmark/DPDFreduction.png\" width=\"300\" height=\"300\" alt=\"benchmark/DPDFreduction.png\"></a> <br/><i>benchmark/DPDFreduction.png</i></center>\n",
      "\n",
      "If we take a slice of this 2D view of the structure factor, we see the phonon peaks on top of the multiphonon background.\n",
      "\n",
      "<center><a href=\"files/benchmark/DPDFreduction_E_7.5.png\"><img src=\"files/benchmark/DPDFreduction_E_7.5.png\" width=\"300\" height=\"300\" alt=\"benchmark/DPDFreduction_E_7.5.png\"></a> <br/><i>benchmark/DPDFreduction_E_7.5.png</i></center>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='sshfs'></a><h3>Explain Wojtek how to mount /SNS wiht SSH</h3>\n",
      "Mount /SNS through SSH, no need to transfer the files to your machine hardrive. You would type in a terminal:\n",
      "\n",
      "<code>sudo mkdir /SNS\n",
      "sudo sshfs -o allow_other w82@analysis.sns.gov:/SNS /SNS</code>\n",
      "\n",
      "If you don't have command sshfs, install it with yum:\n",
      "<code>sudo yum install sshfs</code>\n",
      "\n",
      "After this, you can actually navigave to /SNS as you would if logged in the analysis machines. For instance, to access raw data fo IPTS-12530 of ARCS:\n",
      "<code>cd /SNS/lustre/ARCS/IPTS-12530/data</code>\n",
      "\n",
      "Now that you have the data in a directory (either\n",
      "/home/wojtek/workingdir/ or /SNS/lustre/ARCS/IPTS-12530/data), you have to add it to the list of <i>Data Search Directories</i> in Mantid. To do this, open MantidPlot and then select <i>Manage User Directories</i> from the <i>File</i> menu. You'll get a popup like this:\n",
      "\n",
      "<center><a href=\"files/other/screenshot_manage_user_directories_1.png\"><img src=\"files/other/screenshot_manage_user_directories_1.png\" width=\"300\" height=\"300\" alt=\"other/screenshot_manage_user_directories_1.png\"></a> <br/><i>other/screenshot_manage_user_directories_1.png</i></center></br>\n",
      "\n",
      "Now either type in the path of the directory, or use the <i>Browse To Directory button</i>. Also, be sure to uncheck the <i>Search Data Archive</i> box. You have something like this:\n",
      "\n",
      "<center><a href=\"files/other/screenshot_manage_user_directories_2.png\"><img src=\"files/other/screenshot_manage_user_directories_2.png\" width=\"300\" height=\"300\" alt=\"other/screenshot_manage_user_directories_2.png\"></a> <br/><i>other/screenshot_manage_user_directories_2.png</i></center></br>\n",
      "\n",
      "Now click in the <i>Add Directory</i> button and this directory will be added to the list of <i>Data Search Directories</i>. You can add more directories to the list in the same fashion.\n",
      "\n",
      "Once you have done this, you can use the DPDF algorithm and enter the run numbers for the event Nexus files as usual. Mantid will search in the list of <i>Data Search Directories</i> for the raw data files."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='SectionTag'></a><h2>Section title here</h2>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='SectionTag.subsection1Tag'></a><h3>Subsection 1 title here</h3>\n",
      "Some text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='SectionTag.subsection2Tag'></a><h3>Subsection 2 title here</h3>\n",
      "Some text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='Syntax'></a><h3>Syntax Examples</h3>\n",
      "local link: [link](files/link)</br>\n",
      "remote link: <a href=\"http://ambermd.org/\">http://ambermd.org</a>\n",
      "<font face=\"courier new\"> font face=\"courier new\" </font><br/>\n",
      "$$S_{model}(Q,E)=A(Q)\\cdot S_{elastic}(E) + B(Q)\\cdot S_{simulation}(Q,E)\\otimes S_{elastic}(E) + C(Q)+D(Q)\\cdot E$$\n",
      "<pre> Quoted text </pre>\n",
      "<center><table><tr>\n",
      "<td><a href=\"files/image.png\"><img src=\"files/image.png\" width=\"300\" height=\"250\" alt=\"image here\"></a> <br/>\n",
      "    <i>image caption</i></td>\n",
      "<td>some text</td>\n",
      "</tr></table></center>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}