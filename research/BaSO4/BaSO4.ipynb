{
 "metadata": {
  "name": "",
  "signature": "sha256:1e5ace60d8589e762561115dbef7ba7b4fec79fd67bd702efc0f17525623ae6a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>BaSO4</h1> This notebook continues where \\$PROJD/README_BaSO4.docx, \\$CODED/projects/BaSO4/BaSO4.py, \\$CODED/projects/BaSO4/terminal_commands.sh, and  \\$CODED/projects/BaSO4/mantid_commands.py left.  \n",
      "<a id='Table of Contents'></a><h3>Table of Contents</h3>  \n",
      "<a href='#Syntax'>HTML and Markdown Syntax Examples</a>  \n",
      "<a href='#people'>People</a>  \n",
      "<a href='#paper'>Paper</a>  \n",
      "&nbsp;&nbsp;&nbsp;&nbsp;<a href='#v15'>Version 15</a>  \n",
      "<a href='#QIF'>Q-integrated Fits</a>  \n",
      "<a href='#QDF'>Q-dependent Fits</a>  \n",
      "<a id='boundWater'></a><b>Bound water</b>  \n",
      "<a href='#boundWater.AndrewData'>bound water computed by Andrew</a>  \n",
      "<a href='#boundWater.theory'>Expression for the bound self-incoherent scattering</a>  \n",
      "<a href='#boundWater.boundFlag'>Find hydrogens bound to the surface</a>  \n",
      "<a href='#boundWater.scat'>Itermediate incoherent structure factors</a>  \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='Syntax'></a><h3>HTML and Markdown Syntax Examples</h3>\n",
      "local link: [link](files/link)</br>\n",
      "remote link: <a href=\"http://ambermd.org/\">http://ambermd.org</a>\n",
      "<font face=\"courier new\"> font face=\"courier new\" </font><br/>\n",
      "$$S_{model}(Q,E)=A(Q)\\cdot S_{elastic}(E) + B(Q)\\cdot S_{simulation}(Q,E)\\otimes S_{elastic}(E) + C(Q)+D(Q)\\cdot E$$\n",
      "<pre> Quoted text </pre>\n",
      "<center><table><tr>\n",
      "<td><a href=\"files/image.png\"><img src=\"files/image.png\" width=\"300\" height=\"250\" alt=\"image here\"></a> <br/>\n",
      "    <i>image caption</i></td>\n",
      "<td>some text</td>\n",
      "</tr></table></center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='people'></a><h3>People</h3>\n",
      "Andrew Stack<br/>\n",
      "Eugene Mamontov<br/>\n",
      "David J. Wesolowski <wesolowskid@ornl.gov><br/>\n",
      "Hsiu-wen Wang <wanghw@lanl.gov><br/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='paper'></a><h2>Paper</h2>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='v15'></a><h3>Version 15</h3>\n",
      "Andrew wrote the following email:\n",
      "\n",
      "Attached is the latest version of the QENS measurements on barite.  This manuscript now includes the Q-dependent fits to the QENS data that Jose has calculated using the MD trajectories, the empirical fits have been removed entirely and it has been formatted for submission for PCCP.\n",
      "\n",
      "Right now, the manuscript reads such that we can 1) fit the MD data and 2) we can calculate residence times of water exchange on barite.  I think it could be more convincing if we included in between those two things an empirical fit that showed that the measured qens dynamics were of a similar magnitude as the residence times calculated from the MD simulations.  In past versions of this manuscript, the reviewers all started frothing at the mouth because of our Q-averaged data.  What I have done that is new is included an additional pdf on this e-mail that shows the results of Hsiu-Wen's implementation of the Hall-Ross Jump Diffusion model.\n",
      "\n",
      "What this is is the normal fits to the QENS data using DAVE using one or two Lorentzians, and then fitting the q-dependence of the HWHM as a function of Q^2 using Hsiu-Wen's routine.  The data are noisy and the fits don't quite capture the data.  For 240 K I had to even throw out a data point (at Q^2 = 0.8 1/\u00c5^2) to get any kind of reasonable fit.\n",
      "\n",
      "\n",
      "The results of the fits using either one or two Lorentzians are on page 2 of the pdf.  The top plot on page 2 shows how these Q-dependent fits plot against the original Q-averaged fits (those are green, whereas the new Q-dependent fits for 1 Lor. = blue and the 2 Lor. fits are gray and black).  Not a big difference in relative magnitudes and trends, if we discount the 240 K data.  The bottom plot on page two shows the diffusion coefficient derived from that fit.\n",
      "\n",
      "\n",
      "On pages 3 & 4 I show how the residence times from the 1 Lorentzian (page 3) and 2 Lorenztian (page 4) fits measure against the residence times of water calculated from the MD simulations.  As you might expect based on how well the MD simulations fit the QENS data directly (Figure 3 in the manuscript), the empirical fits represent an average of some number of the residence times of water calculated in the MD.\n",
      "\n",
      "So the big question is, do we include a Q-dependent empirical fit in the manuscript?  I personally think we should do whatever will get the manuscript accepted more quickly.  If I were reading this manuscript, I would want to know that the water exchanges were contributing to the QENS signal though, otherwise why would it be valid to use QENS to validate MD water exchanges?  That suggests perhaps a 1 Lorentzian empirical fit should be shown because it is the best data but the two Lorentzian fit does overlap the barium and sulfate residences very nicely too.  Let me know what you think.  A third way might be to include that stuff in the supplemental information.\n",
      "\n",
      "The files are [jump_diffusion_fits.pdf](files/andrew_paper/qens15/jump_diffusion_fits.pdf), [qens_15.docx](files/andrew_paper/qens15/qens_15.docx), and [qens_15_SI.doc](files/andrew_paper/qens15/qens_15_SI.doc)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='QIF'></a><h3>Q-integrated Fits</h3>\n",
      "\n",
      "Mantid script to Fit with the average Q in the [-0.1, 0.5] meV range.<br/>\n",
      "First, we create a resolution function that has a symmetric energy domain ([-0.5, 0.5]). Otherwise the convolution gives rise to artifacts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create extended and symmetric elastic line\n",
      "# Create the \"right leg\"\n",
      "CloneWorkspace(InputWorkspace='elastic',OutputWorkspace='elastic_extended')\n",
      "Rebin(InputWorkspace='elastic',OutputWorkspace='elastic_extended', Params='-0.1,0.0004,0.5')\n",
      "Rebin(InputWorkspace='elastic',OutputWorkspace='elastic_extended', Params='-0.5,0.0004,0.5')\n",
      "# Create the \"left leg\"\n",
      "CloneWorkspace(InputWorkspace='elastic',OutputWorkspace='junk')\n",
      "Rebin(InputWorkspace='junk', OutputWorkspace='junk', Params='0.1,0.0004,0.5')\n",
      "ScaleX(InputWorkspace='junk', OutputWorkspace='junk', Factor=-1.0, Operation='Multiply')\n",
      "Rebin(InputWorkspace='junk', OutputWorkspace='junk', Params='-0.5,0.0004,0.5')\n",
      "# Add both workspaces and save\n",
      "Plus(LHSWorkspace='elastic_extended', RHSWorkspace='junk', OutputWorkspace='elastic_extended')\n",
      "expdir='/projects/research/BaSO4/expdata'\n",
      "SaveNexus(InputWorkspace='elastic_extended', Filename='{0}/elastic_extended.nxs'.format(expdir))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now use the extended elastic line to produce the fits"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expdir='/projects/research/BaSO4/expdata'\n",
      "simdir='/projects/research/BaSO4/andrew_simulation'\n",
      "e_range=(-0.1,0.0004,0.5)\n",
      "LoadNexus(Filename='%s/elastic.nxs'%expdir, OutputWorkspace='elastic')\n",
      "LoadNexus(Filename='%s/elastic_extended.nxs'%expdir, OutputWorkspace='elastic_extended')\n",
      "for temp in '230 240 260 282 300'.split():\n",
      "    LoadDaveGrp(Filename='%s/q%s.dat'%(expdir,temp), OutputWorkspace='exp%s'%temp, XAxisUnits='DeltaE', YAxisUnits='Empty', IsMicroEV=1)  # experiment\n",
      "    LoadSassena(Filename='%s/fqt_inc_T%s_water.h5'%(simdir,temp),OutputWorkspace='sim%s'%temp,TimeUnit=0.1) # load simulated data\n",
      "    Rebin(InputWorkspace='sim%s_fqt.Re'%temp, OutputWorkspace='sim%s_fqt.Re'%temp, Params=[-5000,0.1,5000])  # Eliminate wiggly tails\n",
      "    SassenaFFT(InputWorkspace='sim%s'%temp, FFTonlyRealPart=1, DetailedBalance=1, Temp=float(temp))\n",
      "    Scale(InputWorkspace='sim%s_sqw'%temp,Factor=1.0e-08, Operation='Multiply',OutputWorkspace='sim%s_sqw'%temp) # More manageable for the fitting procedure\n",
      "    fitstr='name=TabulatedFunction,Workspace=elastic,WorkspaceIndex=0,Scaling=1;(composite=Convolution,FixResolution=true,NumDeriv=true;name=TabulatedFunction,Workspace=elastic_extended,WorkspaceIndex=0,Scaling=1;name=TabulatedFunction,Workspace=sim%s_sqw,WorkspaceIndex=0,Scaling=1);name=LinearBackground,A0=0,A1=0'%temp\n",
      "    Fit(fitstr, InputWorkspace='exp%s'%temp, WorkspaceIndex=0, CreateOutput=1, OutputCompositeMembers=1, startX=e_range[0], endX=e_range[-1])\n",
      "    for suffix in ('Workspace', 'Parameters', 'NormalisedCovarianceMatrix'):\n",
      "\tRenameWorkspace(InputWorkspace='exp%s_%s'%(temp,suffix), OutputWorkspace='fit_temp_%s_%s'%(temp,suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I saved the Mantid session under [fit_integratedQ](files/andrew_simulation/fit_integratedQ). This should also contain associated plots I did in the session.\n",
      "<center><table><tr>\n",
      "    <td><center><a href=\"files/andrew_simulation/fit_integratedQ/fits.jpeg\"><img src=\"files/andrew_simulation/fit_integratedQ/fits.jpeg\"  height=\"100\" width=\"150\" align=\"center\"></a><br/><i>andrew_simulation/fit_integratedQ/fits.jpeg</i></center></td>\n",
      "    <td><center><a href=\"files/andrew_simulation/fit_integratedQ/chi2_fit_Qint.png\"><img src=\"files/andrew_simulation/fit_integratedQ/chi2_fit_Qint.png\" height=\"100\" width=\"150\" align=\"center\"></a> <br/><i>andrew_simulationfit_integratedQ/chi2_fit_Qint.png(agr)</i></center></td>\n",
      "</tr></table></center>\n",
      "\n",
      "Next, we save the fitted parameters in file [parameters.dat](files/andrew_simulation/fit_integratedQ/parameters.dat); see below script."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "''' we now the order of the parameters in the *_Parameters workspaces:\n",
      "Example:\n",
      "             Name         Value       Error\n",
      "   f0.Scaling\t        0.298252\t0.000877252\n",
      "   f1.Scaling\t        0.00427234\t1.12765e-05\n",
      "   f2.A0\t            8.3584e-05\t2.60375e-05\n",
      "   f2.A1\t            0.0018324\t7.02565e-05\n",
      "   Cost function value\t1.6314\t    0\n",
      "'''\n",
      "buffer = '# T       A       Error      B      Error    intercept    Error     slope     Error     Chi2     Error\\n'\n",
      "for temp in '230 240 260 282 300'.split():\n",
      "    ws = mtd[ 'fit_temp_{0}_Parameters'.format( temp ) ]\n",
      "    buffer += ' {0}'.format( temp )\n",
      "    nrows = ws.rowCount()\n",
      "    for irow in range( nrows ):\n",
      "        if irow==1: continue  # Skip the parameter of the resolution, which is fixed to one\n",
      "        row = ws.row( irow )\n",
      "        buffer += ' {0:5.3e} {1:5.3e}'.format( row['Value'], row['Error'] )\n",
      "    buffer += '\\n'\n",
      "open( '/projects/research/BaSO4/andrew_simulation/fit_integratedQ/parameters.dat', 'w' ).write( buffer )       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#Table of Contents'>Top</a>)<a id='QDF'></a><h3>Q-dependent Fits</h3>\n",
      "Directory <i>expdata/qdep/</i> contains Q-dependent reduced files. Values 0.5 to 0.9 are good for the fitting. Q=0.3 did not provide a good fit for the two-Lorentzian method, and Q=1.1 contains a Bragg peak, so Q>0.9 was unusable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In Chadwick <i>/data/jbq/projects/research/BaSO4/andrew_simulation/qdep/</i>, submit Sassena simulations with Q values in the [0.2, 1.3] range every Q=0.02, for a total of 56 values.<br/>\n",
      "Once we bring the Sassena output, we stamp a version and reorder by Q-modulus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cd /projects/research/BaSO4/andrew_simulation/qdep\n",
      "for temp in 230 240 260 282 300;do\n",
      "  python ~/code/python/mysassena/version.py --filename fqt_inc_T${temp}_water.h5\n",
      "  python ~/code/python/mysassena/orderByQmodulus.py  --filename fqt_inc_T${temp}_water.h5 --outfile junk.h5\n",
      "  /bin/mv junk.h5 fqt_inc_T${temp}_water.h5\n",
      "done"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mantid script to do the fitting to the different temperature and Q-values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expdir='/projects/research/BaSO4/expdata/qdep'\n",
      "simdir='/projects/research/BaSO4/andrew_simulation/qdep'\n",
      "LoadDaveGrp(Filename='%s/resolution.dat'%expdir,OutputWorkspace='elastic',XAxisUnits='DeltaE',YAxisUnits='Empty',IsMicroEV=1)\n",
      "endX=0.5\n",
      "Rebin(InputWorkspace='elastic',OutputWorkspace='elastic',Params=(-0.2,0.0004,endX))\n",
      "\n",
      "for temp in '230 240 260 282 300'.split():\n",
      "    LoadDaveGrp(Filename='%s/q%s.dat'%(expdir,temp),OutputWorkspace='exp%s'%temp,XAxisUnits='DeltaE',YAxisUnits='Empty',IsMicroEV=1) # load experimental data\n",
      "    SmoothData(InputWorkspace='exp%s'%temp,Npoints=3,OutputWorkspace='exp%s'%temp) # correct the few energy bins with no intensity\n",
      "    Rebin(InputWorkspace='exp%s'%temp,OutputWorkspace='exp%s'%temp,Params=(-0.2,0.0004,endX))\n",
      "    LoadSassena(Filename='%s/fqt_inc_T%s_water.h5'%(simdir,temp),OutputWorkspace='sim%s'%temp,TimeUnit=0.1) # load simulated data\n",
      "    SassenaFFT(InputWorkspace='sim%s'%temp,FFTonlyRealPart=1,DetailedBalance=1,Temp=float(temp))\n",
      "    #Q values start at 0.2, end in 1.3, every 0.02. We want Q-values 0.3, 0.5, 0.7, 0.9, and 1.1. For Q=0.5, we sum spectra in the [0.4, 0.6] range\n",
      "    for iQ in range(5):\n",
      "        ExtractSingleSpectrum(InputWorkspace='elastic',WorkspaceIndex=iQ,OutputWorkspace='elastic_iQ')\n",
      "\tScaleX(InputWorkspace='elastic_iQ',Factor=-1.0,Operation='Multiply',OutputWorkspace='resolution_iQ')\n",
      "        central_Q=0.3+iQ*0.2\n",
      "        outw='simQ%3.1fT%s'%(central_Q,temp)\n",
      "        SumSpectra(InputWorkspace='sim%s_sqw'%temp, StartWorkspaceindex=iQ*10, EndWorkspaceindex=(1+iQ)*10, OutputWorkspace=outw)\n",
      "        Rebin(InputWorkspace=outw,OutputWorkspace=outw,Params=(-0.2,0.0004,endX))\n",
      "        Scale(InputWorkspace=outw,OutputWorkspace=outw, Factor=1e-10, Operation='Multiply')\n",
      "\tfitstr='name=TabulatedFunction,Workspace=elastic_iQ,Scaling=1,constraints=(1e-03<Scaling);(composite=Convolution;name=TabulatedFunction,Workspace=elastic_iQ,Scaling=1,ties=(Scaling=1);name=TabulatedFunction,Workspace=simQ%3.1fT%s,Scaling=1,constraints=(1e-05<Scaling));name=LinearBackground,A0=1e-05,A1=1e-05'%(central_Q,temp)\n",
      "\tprint fitstr\n",
      "        Fit(fitstr,InputWorkspace='exp%s'%temp,WorkspaceIndex=iQ,CreateOutput=1, OutputCompositeMembers=1, startX=-0.2, endX=endX)\n",
      "        for suffix in ('Workspace', 'Parameters', 'NormalisedCovarianceMatrix'):\n",
      "\t    RenameWorkspace(InputWorkspace='exp%s_%s'%(temp,suffix), OutputWorkspace='fit_temp_%s_Q_%s_%s'%(temp,str(central_Q),suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After executing the script in Mantidplot, we save the Mantid session as [fqt_fits.mantid](files/andrew_simulation/qdep/fqt_fits/fqt_fits.mantid) along with all the auxiliary files.\n",
      "\n",
      "We save the fitting parameters into files like <i>andrew_simulation/qdep/fqt_fits/fit_temp_230_Parameters.dat</i>, one for each temperature with the help of the below script:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pdb import set_trace as tr\n",
      "import numpy as np\n",
      "from mantid.simpleapi import LoadNexus\n",
      "rows={'elastic_scaling':0, 'simulation_scaling':2, 'background_intercept':3, 'background_slope':4, 'Chi2':5 }\n",
      "indexes = rows.values()\n",
      "indexes.sort()\n",
      "rootd='/projects/research/BaSO4/andrew_simulation/qdep/fqt_fits'\n",
      "qvalues=np.array([0.3, 0.5, 0.7, 0.9, 1.1]); nq=len(qvalues)\n",
      "tvalues=np.array([230,240,260,282,300]); nt=len(tvalues)\n",
      "\n",
      "for it in range(nt):\n",
      "    buf='# Q elastic_scaling simulation_scaling background_intercept background_slope Chi2\\n'\n",
      "    t=tvalues[it]\n",
      "    for iq in range(nq):\n",
      "        q=qvalues[iq]\n",
      "        buf += ' {0}'.format(q)\n",
      "        wsname='fit_temp_%s_Q_%s_Parameters'%(str(t),str(q))\n",
      "        ws=LoadNexus('%s/%s.nxs'%(rootd,wsname))\n",
      "        for ix in indexes:\n",
      "            buf += ' {0}'.format( ws.row(ix)['Value'] )\n",
      "        buf += '\\n'\n",
      "    open('{0}/fit_temp_{1}_Parameters.dat'.format(rootd,t),'w').write(buf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's the plot of the Chi2 versus Q for the different temperatures. We also plot the worst fit, showing simulation with smaller broadening than experiment\n",
      "<center><table><tr>\n",
      "<td><a href=\"files/andrew_simulation/qdep/fqt_fits/fit_Parameters_Chi2.png\"><img src=\"files/andrew_simulation/qdep/fqt_fits/fit_Parameters_Chi2.png\" width=\"500\" height=\"400\" alt=\"andrew_simulation/qdep/fqt_fits/fit_Parameters_Chi2.png\"></a> <br/>\n",
      "    <i>andrew_simulation/qdep/fqt_fits/fit_Parameters_Chi2.agr(png)</i></td>\n",
      "<td><a href=\"files/andrew_simulation/qdep/fqt_fits/fit_temp_240_Q_1.1_Workspace.png\"><img src=\"files/andrew_simulation/qdep/fqt_fits/fit_temp_240_Q_1.1_Workspace.png\" width=\"500\" height=\"400\" alt=\"andrew_simulation/qdep/fqt_fits/fit_temp_240_Q_1.1_Workspace.png\"></a> <br/>\n",
      "    <i>andrew_simulation/qdep/fqt_fits/fit_temp_240_Q_1.1_Workspace.png</i></td>\n",
      "</tr></table></center>\n",
      "\n",
      "Next, we plot several quantities of interest. First, a function to plot several quantities versus temperature and Q"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_parameter(name):\n",
      "    import matplotlib.pyplot as plt\n",
      "    import matplotlib.cm as cm\n",
      "    import numpy as np\n",
      "    from mantid.simpleapi import LoadNexus\n",
      "    allowed_names=('elastic_scaling', 'simulation_scaling', 'background_intercept', 'background_slope', 'Chi2')\n",
      "    rows={'elastic_scaling':0, 'simulation_scaling':2, 'background_intercept':3, 'background_slope':4, 'Chi2':5 }\n",
      "    rootd='/projects/research/BaSO4/andrew_simulation/qdep/fqt_fits'\n",
      "    qvalues=np.array([0.3, 0.5, 0.7, 0.9, 1.1]); nq=len(qvalues)\n",
      "    tvalues=np.array([230,240,260,282,300]); nt=len(tvalues)\n",
      "    parvals=-np.ones(shape=(nq,nt))  # -1 indicates not filled\n",
      "    for it in range(nt):\n",
      "        buf='# Q f0.Scaling f1.f0.Scaling f1.f1.Scaling f2.A0 f2.A1 Chi\\n'\n",
      "        t=tvalues[it]\n",
      "        for iq in range(nq):\n",
      "            q=qvalues[iq]\n",
      "            wsname='fit_temp_%s_Q_%s_Parameters'%(str(t),str(q))\n",
      "            ws=LoadNexus('%s/%s.nxs'%(rootd,wsname))\n",
      "            parvals[iq][it]=ws.cell(rows[name],1)\n",
      "    fig, ax = plt.subplots()\n",
      "    cax = ax.imshow(parvals, extent=(qvalues.min(), qvalues.max(), tvalues.min(), tvalues.max()),\n",
      "                    interpolation=None, cmap=cm.gist_rainbow, aspect='auto')\n",
      "    ax.set_title(name+' versus Q and temperature'); ax.set_xlabel('Q'); ax.set_ylabel('T')\n",
      "    cbar = fig.colorbar(cax)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We plot those quantities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for name in ('elastic_scaling', 'simulation_scaling', 'background_intercept', 'background_slope', 'Chi2'):\n",
      "    plot_parameter(name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We calculate the percent of the intensity due to the simulation, elastic line, and background. For that, we have to integrate each signal separately over the energy domainpercent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import numpy as np\n",
      "from mantid.simpleapi import LoadNexus, ConvertToHistogram, Integration\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "from pdb import set_trace as tr\n",
      "\n",
      "rootd='/projects/research/BaSO4/andrew_simulation/qdep/fqt_fits'\n",
      "qvalues=np.array([0.3, 0.5, 0.7, 0.9, 1.1]); nq=len(qvalues)\n",
      "tvalues=np.array([230,240,260,282,300]); nt=len(tvalues)\n",
      "elastic_intensity=-np.ones(shape=(nq,nt))  # -1 indicates not filled\n",
      "simulation_intensity=-np.ones(shape=(nq,nt))\n",
      "background_intensity=-np.ones(shape=(nq,nt))\n",
      "for iq in range(nq):\n",
      "    q=qvalues[iq]\n",
      "    for it in range(nt):\n",
      "        t=tvalues[it]\n",
      "        fname='fit_temp_%s_Q_%s_Workspace'%(str(t),str(q))\n",
      "        LoadNexus(Filename='%s/%s.nxs'%(rootd,fname), OutputWorkspace='fit')\n",
      "        ConvertToHistogram(InputWorkspace='fit', OutputWorkspace='fit')\n",
      "        intensities=Integration(InputWorkspace='fit')\n",
      "        total_I=intensities.dataY(1)[0]\n",
      "        elastic_intensity[iq][it]=100*intensities.dataY(3)[0]/total_I\n",
      "        background_intensity[iq][it]=100*intensities.dataY(6)[0]/total_I\n",
      "        simulation_intensity[iq][it]=100-elastic_intensity[iq][it]-background_intensity[iq][it]\n",
      "for name,array in zip(['Elastic Intensity', 'Simulation Intensity', 'Background Intensity'],\n",
      "                      [elastic_intensity,simulation_intensity,background_intensity]):\n",
      "    fig, ax = plt.subplots()\n",
      "    cax = ax.imshow(array, extent=(qvalues.min(), qvalues.max(), tvalues.min(), tvalues.max()),\n",
      "                    interpolation=None, cmap=cm.gist_rainbow, aspect='auto')\n",
      "    ax.set_title(name+' versus Q and temperature'); ax.set_xlabel('Q'); ax.set_ylabel('T')\n",
      "    cbar = fig.colorbar(cax)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Note:</b> The previously calculated intensities are restricted to the [-0.2, 0.5]meV region. Thus, intensities outside this region is 'lost'. We try to incorporate this intensity by assuming it is due to the simulated signal. Thus, we calculate what fraction of the simulated intensity is outside the considered region and save to file [lost_fraction.dat](files/andrew_simulation/qdep/lost_fraction.dat)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expdir='/projects/research/BaSO4/expdata/qdep'\n",
      "simdir='/projects/research/BaSO4/andrew_simulation/qdep'\n",
      "LoadDaveGrp(Filename='%s/resolution.dat'%expdir,OutputWorkspace='elastic',XAxisUnits='DeltaE',YAxisUnits='Empty',IsMicroEV=1)\n",
      "endX=0.5\n",
      "Rebin(InputWorkspace='elastic',OutputWorkspace='elastic',Params=(-0.2,0.0004,endX))\n",
      "\n",
      "buffer='# fraction of simulated intensity outside the [-0.2, 0.5]meV range\\n'\n",
      "for temp in '230 240 260 282 300'.split():\n",
      "    LoadDaveGrp(Filename='%s/q%s.dat'%(expdir,temp),OutputWorkspace='exp%s'%temp,XAxisUnits='DeltaE',YAxisUnits='Empty',IsMicroEV=1) # load experimental data\n",
      "    SmoothData(InputWorkspace='exp%s'%temp,Npoints=3,OutputWorkspace='exp%s'%temp) # correct the few energy bins with no intensity\n",
      "    Rebin(InputWorkspace='exp%s'%temp,OutputWorkspace='exp%s'%temp,Params=(-0.2,0.0004,endX))\n",
      "    LoadSassena(Filename='%s/fqt_inc_T%s_water.h5'%(simdir,temp),OutputWorkspace='sim%s'%temp,TimeUnit=0.1) # load simulated data\n",
      "    SassenaFFT(InputWorkspace='sim%s'%temp,FFTonlyRealPart=1,DetailedBalance=1,Temp=float(temp))\n",
      "    for iQ in range(5):\n",
      "        ExtractSingleSpectrum(InputWorkspace='elastic',WorkspaceIndex=iQ,OutputWorkspace='elastic_iQ')\n",
      "\tScaleX(InputWorkspace='elastic_iQ',Factor=-1.0,Operation='Multiply',OutputWorkspace='resolution_iQ')\n",
      "        central_Q=0.3+iQ*0.2\n",
      "        outw='simQ%3.1fT%s'%(central_Q,temp)\n",
      "        SumSpectra(InputWorkspace='sim%s_sqw'%temp, StartWorkspaceindex=iQ*10, EndWorkspaceindex=(1+iQ)*10, OutputWorkspace=outw)\n",
      "\tScale(InputWorkspace=outw,OutputWorkspace=outw, Factor=1e-10, Operation='Multiply')\n",
      "\tConvertToHistogram(InputWorkspace=outw,OutputWorkspace=outw)\n",
      "\tws1=Integration(InputWorkspace=outw,RangeLower=-0.2, RangeUpper=endX)\n",
      "\tws2=Integration(InputWorkspace=outw)\n",
      "\tbuffer+='%3.1f %s %5.3f\\n'%(central_Q, temp, 1-ws1.dataY(0)[0]/ws2.dataY(0)[0])\n",
      "open('%s/lost_fraction.dat'%simdir, 'w').write(buffer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We plot the percent of the simulated intensity outside the [-0.2, 0.5] range"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "from utilities.readingWritingFiles import read_column\n",
      "qvalues=np.array([0.3, 0.5, 0.7, 0.9, 1.1]); nq=len(qvalues)\n",
      "tvalues=np.array([230,240,260,282,300]); nt=len(tvalues)\n",
      "lost_fraction=read_column('/projects/research/BaSO4/andrew_simulation/qdep/lost_fraction.dat',3,isFloat=1)\n",
      "lost_fraction=100*np.array(lost_fraction).reshape(nq,nt).transpose()\n",
      "fig, ax = plt.subplots()\n",
      "cax = ax.imshow(lost_fraction, extent=(qvalues.min(), qvalues.max(), tvalues.min(), tvalues.max()),interpolation=None, cmap=cm.gist_rainbow, aspect='auto')\n",
      "ax.set_title('Simulated percent Intensity outside the [-0.2, 0.5]meV range'); ax.set_xlabel('Q'); ax.set_ylabel('T')\n",
      "cbar = fig.colorbar(cax)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now calculate percent of the intensity due to the slope, elastic line, and background taking into account the intensity lost by the simulated component outside the considered region."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import numpy as np\n",
      "from mantid.simpleapi import LoadNexus, ConvertToHistogram, Integration\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "from utilities.readingWritingFiles import read_column\n",
      "\n",
      "qvalues=np.array([0.3, 0.5, 0.7, 0.9, 1.1]); nq=len(qvalues)\n",
      "tvalues=np.array([230,240,260,282,300]); nt=len(tvalues)\n",
      "lost_fraction=read_column('/projects/research/BaSO4/andrew_simulation/qdep/lost_fraction.dat',3,isFloat=1)\n",
      "lost_fraction=np.array(lost_fraction).reshape(nq,nt).transpose()\n",
      "rootd='/projects/research/BaSO4/andrew_simulation/qdep/fqt_fits'\n",
      "elastic_intensity=-np.ones(shape=(nq,nt))  # -1 indicates not filled\n",
      "simulation_intensity=-np.ones(shape=(nq,nt))\n",
      "background_intensity=-np.ones(shape=(nq,nt))\n",
      "for iq in range(nq):\n",
      "    q=qvalues[iq]\n",
      "    for it in range(nt):\n",
      "        t=tvalues[it]\n",
      "        fname='fit_temp_%s_Q_%s_Workspace'%(str(t),str(q))\n",
      "        LoadNexus(Filename='%s/%s.nxs'%(rootd,fname), OutputWorkspace='fit')\n",
      "        ConvertToHistogram(InputWorkspace='fit', OutputWorkspace='fit')\n",
      "        intensities=Integration(InputWorkspace='fit')\n",
      "        total_I=intensities.dataY(1)[0]\n",
      "        ei=intensities.dataY(3)[0]/total_I\n",
      "        bi=intensities.dataY(6)[0]/total_I\n",
      "        si=(1-ei-bi)/(1-lost_fraction[iq][it])  #add the lost fraction to the simulated component\n",
      "        total_I= ei+bi+si   #recalculate the total intensity\n",
      "        elastic_intensity[iq][it]=100*ei/total_I\n",
      "        background_intensity[iq][it]=100*bi/total_I\n",
      "        simulation_intensity[iq][it]=100*si/total_I\n",
      "\n",
      "for name,array in zip(['Elastic Intensity', 'Simulation Intensity', 'Background Intensity'],\n",
      "                      [elastic_intensity,simulation_intensity,background_intensity]):\n",
      "    fig, ax = plt.subplots()\n",
      "    cax = ax.imshow(array, extent=(qvalues.min(), qvalues.max(), tvalues.min(), tvalues.max()),\n",
      "                    interpolation=None, cmap=cm.gist_rainbow, aspect='auto')\n",
      "    ax.set_title(name+' versus Q and temperature'); ax.set_xlabel('Q'); ax.set_ylabel('T')\n",
      "    cbar = fig.colorbar(cax)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mark suggested to fit the data with parameter scaling of the simulation independent of Q, that is,\n",
      "$$S_{model}(Q,E)=A(Q) \\cdot S_{elastic}(Q,E)+B \\cdot S_{sim}(Q,E) \\otimes S_{elastic}(Q,E) + C(Q) + D(Q) \\cdot E$$\n",
      "\n",
      "We calculate the convolved spectrum from simulation and the resolution function, files [res_x_sqt_inc_T230_water.nxs](files/andrew_simulation/qdep/res_x_sqt_inc_T230_water.nxs) and similar for other temperatures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from camm.simulation.src.scattering.sassenatasks import genSQE\n",
      "from camm.simulation.src.beamline.convolve import convolution\n",
      "\n",
      "expdir='/projects/research/BaSO4/expdata/qdep'\n",
      "simdir='/projects/research/BaSO4/andrew_simulation/qdep'\n",
      "\n",
      "for temp in [230,240,260,282,300]:\n",
      "    hdfname=simdir+'/fqt_inc_T%3d_water.h5'%temp\n",
      "    simulated=simdir+'/sqt_inc_T%3d_water.nxs'%temp\n",
      "    kwargs={ 'LoadSassena':{'TimeUnit':0.1,}, 'SassenaFFT':{'Temp':temp,} }\n",
      "    genSQE(hdfname,simulated,rebinQ='0.2 0.2 1.2', scale=1e-10, **kwargs)  # simulated S(Q,E)\n",
      "    convolution(simulated, expdir+'/resolution.nxs', expdir+'/exp%d.nxs'%temp, simdir+'/res_x_sqt_inc_T%d_water.nxs'%temp) # convolution with resolution function"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use Dakota to fit the convolved spectra to the experimental data. File [dakota_init.in](files/andrew_simulation/qdep/dakota_init.in) describes the fitting model. We have five parameters for the elastic line (one per Q-value), two parameters for the linear background, one parameter for the simulation scaling, and one parameter for shifts along the energy axis. We need external python code to calculate Chi2, [opt_driver.py](files/andrew_simulation/qdep/opt_driver.py)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from camm.simulation.src.beamline.assemblemodel import modelB_freeE_C\n",
      "\n",
      "expdir='/projects/research/BaSO4/expdata/qdep'\n",
      "simdir='/projects/research/BaSO4/andrew_simulation/qdep'\n",
      "\n",
      "model='b0=1.3211; b1=0.00; e0.0=0.99; e0.1=0.99; e0.2=0.99; e0.3=0.99; e0.4=0.99; c0=2.3' #from params.in\n",
      "\n",
      "modelB_freeE_C(model, '%s/resolution.nxs'%expdir, '%/res_x_sqt_inc_T230_water.nxs'%simdir, '%s/assembled_inc_T230_water.nxs'%simdir, expdata=None, costfile=None, derivdata=None, derivexclude=[], doshift=True)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#boundWater'>Top</a>)<a id='boundWater.AndrewData'></a><h3>Bound water computed by Andrew</h3>\n",
      "Andrew calculated for each water oxygen wheter it is \"bound\" to the Barite surface at every recorded frame of the simulation at 300K.\n",
      "\n",
      "In subdirectory <i>boundWater/</i>, file <code>300.bytimestep</code> contains a series of lines. The first item on each line is the timestep number (in fs, reported every 100 fs).  The rest of each line is a list of the oxygens on water that are associated with the surface at that timestep.\n",
      "\n",
      "In subdirectory <i>boundWater/indata/</i>, there are files whose name is the water oxygen number, and the file contents are a timestep and a 1 or a 0. It is 1 for bound to the surface, 0 for not bound.  \n",
      "\n",
      "Acalculation of the percent time spent by each oxygen to the surface reveals that all oxygens spend at least 40% of their times in the bound state. See the cummulative histogram:\n",
      "\n",
      "<center><a href=\"files/boundWater/boundOccurrence.png\"><img src=\"files/boundWater/boundOccurrence.png\" width=\"500\" height=\"400\" alt=\"boundWater/boundOccurrence.png\"></a>  <i>boundWater/boundOccurrence.png</i></center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#boundWater'>Top</a>)<a id='boundWater.theory'></a><h3>Expression for the bound self-incoherent scattering</h3>\n",
      "\n",
      "The expression for the auto-correlation of a single particle is given by  \n",
      "$G(\\vec{r},t)=\\langle \\int d\\vec{r}' \\delta(\\vec{r}'-\\vec{R}(t_0)) \\delta(\\vec{r}'+ \\vec{r} -\\vec{R}(t_0+t)) \\rangle_{t_0} = \n",
      "\\langle \\rho(\\vec{r}',t_0) \\rho(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r},t_0}$   **(Eq.1)**\n",
      "\n",
      "where $\\vec{R}(t)$ denotes the position of the particle at time $t$, and $\\rho(\\vec{r},t)$ the \"one-particle density\"\n",
      "\n",
      "$\\rho(\\vec{r},t)=\\delta(\\vec{r}-\\vec{R}(t))$  **(Eq.2)**\n",
      "\n",
      "We divide the volume in two regions, one which we consider as bound to the surface, and the rest as unbound. We define a flag function $s(\\vec{r})$ equal to 1 if $\\vec{r}$ is inside the region which we consider bound the surface. For instance, if we have an infinite planar surface at $z=0$, then $s(x,y,z)=1$ only if $z < a$, where $a$ is some distance cut-off from the surface. We thus divide the density into a bound and unbound density.\n",
      "\n",
      "$\\rho(\\vec{r},t) = s(\\vec{r})\\rho(\\vec{r},t) + (1-s(\\vec{r}))\\rho(\\vec{r},t) = \n",
      "\\rho_b(\\vec{r},t) + \\rho_u(\\vec{r},t)$ **(Eq.3)**\n",
      "\n",
      "Now the scattering is partitioned into four components:\n",
      "\n",
      "$G(\\vec{r},t) = \\langle \\rho_b(\\vec{r}',t_0) \\rho_b(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r}',t_0} +\n",
      "\\langle \\rho_b(\\vec{r}',t_0) \\rho_u(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r}',t_0} +\n",
      "\\langle \\rho_u(\\vec{r}',t_0) \\rho_b(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r}',t_0} +\n",
      "\\langle \\rho_u(\\vec{r}',t_0) \\rho_u(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r}',t_0}$ **(Eq.4)**\n",
      "\n",
      "We are interested in the first term, interpreted as the self-correlation arising in the \"bound volume\".\n",
      "$G_{bb}(\\vec{r},t) = \n",
      "\\langle \\rho_b(\\vec{r}',t_0) \\rho_b(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r},t_0} =\n",
      "\\langle s(\\vec{r}') s(\\vec{r}'+\\vec{r}) \\rho(\\vec{r}',t_0) \\rho(\\vec{r}'+\\vec{r},t_0+t) \\rangle_{\\vec{r}',t_0}$ **(Eq.5)**\n",
      "\n",
      "Inserting Eq.2 in this equation, we have:\n",
      "\n",
      "$\\langle s(\\vec{r}') s(\\vec{r}'+\\vec{r}) \\delta(\\vec{r}'-\\vec{R}(t_0)) \\delta(\\vec{r}'+\\vec{r}-\\vec{R}(t_0+t))\\rangle_{\\vec{r}',t_0} =\n",
      "\\langle s(\\vec{R}(t_0)) s(\\vec{R}(t_0+t)) \\delta(\\vec{r}'-\\vec{R}(t_0)) \\delta(\\vec{r}'+\\vec{r}-\\vec{R}(t_0+t))\\rangle_{\\vec{r}',t_0}$  **(Eq.6)**\n",
      "\n",
      "We now define a flag function for the particle that denotes whether the particle is bound or unbound at time $t$:\n",
      "\n",
      "$s(t) \\equiv s(\\vec{R}(t))$  **(Eq.7)**\n",
      "\n",
      "The self-incoherent signal arising only from the bound volume is the Fourier transform of $G_{bb}(\\vec{r},t)$:\n",
      "\n",
      "$S_{bb}(\\vec{Q},t) = \\langle s(t_0)s(t_0+t) e^{\\vec{Q}(\\vec{R}(t_0)-\\vec{R}(t_0+t))} \\rangle_{t_0}$ **(Eq.8)**\n",
      "\n",
      "which is the equation that we will use. Note that in between times $t_0$ and $t_0+t$ the particle may have abandoned the bound volume, but then returned. We do now require to know the history of the particle in between $t_0$ and $t_0+t$, but only its state at the \"end-points\".\n",
      "\n",
      "Also note that the total signal is not just the sum of the signals from the bound and unbound volumes. There are two cross terms (see Eq.4) arising from water adsorption and release from the surface. We can write:\n",
      "\n",
      "$S(\\vec{Q},t) = S_{bb}(\\vec{Q},t) + S_{bu}(\\vec{Q},t) + S_{ub}(\\vec{Q},t) + S_{uu}(\\vec{Q},t)$ **(Eq.9)**  \n",
      "\n",
      "Assuming these functions describe the relaxation of single diffusive events, we interpret as:\n",
      "\n",
      "* $S_{bb}(\\vec{Q},t)$ difussion on the surface\n",
      "* $S_{bu}(\\vec{Q},t)$ water release from the surface\n",
      "* $S_{ub}(\\vec{Q},t)$ water adsorption to the surface\n",
      "* $S_{uu}(\\vec{Q},t)$ diffusion in the bulk\n",
      "\n",
      "We assume that multiple diffusive events, such as water release followed by adsorption, contribute much less than single diffusive events to these structure factors."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#boundWater'>Top</a>)<a id='boundWater.boundFlag'></a><h3>Find hydrogens bound to the surface</h3>\n",
      "\n",
      "In subdirectory <i>boundWater/</i>, we begin by scanning file <code>300.bytimestep</code> which contains for each frame the atomic numbers for the oxygens bound to the surface. Then, we create file <code>300.bytimestep.Hydr</code> containing for each frame the atomic numbers for the hydrogens bound to the surface.\n",
      "\n",
      "We use script [findBoundHydrogens.py](boundWater/findBoundHydrogens.py) to generate <code>300.bytimestep.Hydr</code>.\n",
      "\n",
      "<code>python findBoundHydrogens.py # generates 300.bytimestep.Hydr</code>\n",
      "\n",
      "Next, we create for each frame a line containing 730 entries, each entry a \"1\" or a \"0\", depending on whether each water hydrogen is bound to the surface. We use script [createHydrBoundFlagTraj.py](boundWater/createHydrBoundFlagTraj.py).\n",
      "\n",
      "<code>python createHydrBoundFlagTraj.py # generates 300.boundFlag.Hydr.dat</code>\n",
      "\n",
      "The steps that [createHydrBoundFlagTraj.py](boundWater/createHydrBoundFlagTraj.py) carries out:\n",
      "\n",
      "1. Read 300.pdb file; extract atom numbers for water hydrogens\n",
      "2. Read 300.bytimestep.Hydr. For each frame, create a line containing \"1\" and \"0\", as many as water hydrogens.\n",
      "3. Save the line to file 300.boundFlag.Hydr.dat\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(<a href='#boundWater'>Top</a>)<a id='boundWater.scat'></a><h3>Itermediate incoherent structure factors</h3>\n",
      "\n",
      "(In <i>boundWater/</i>)  \n",
      "With script [calculateII.py](files/calculateII.py), we calculate the following structure factors in the Q-range <code>[0.45, 0.95]</code> every <code>0.05</code>:  \n",
      "\n",
      "* $I_{bb}(Q,t)$; file <i>fqtYY_inc.h5</i>\n",
      "* $I_{bu}(Q,t)$; file <i>fqtYN_inc.h5</i>\n",
      "* $I_{ub}(Q,t)$; file <i>fqtNY_inc.h5</i>\n",
      "* $I_{uu}(Q,t)$; file <i>fqtNN_inc.h5</i>\n",
      "* $I(Q,t) = I_{bb}(Q,t) + I_{bu}(Q,t) + I_{ub}(Q,t) + I_{uu}(Q,t)$; file <i>fqt_inc.h5</i>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}